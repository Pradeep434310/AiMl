{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import math\nimport csv\nfrom collections import Counter\n\ndef load_csv(filename):\n    lines=csv.reader(open(filename,\"r\"));\n    dataset = list(lines)\n    headers = dataset.pop(0)\n    return dataset,headers\n\nclass Node:\n    def __init__ (self,attribute):\n        self.attribute=attribute\n        self.children=[]\n        self.answer=\"\"\n\ndef subtables(data,col,delete):\n   \n    colwise_data = {}\n    for i, row in enumerate(data):\n        if row[col] not in colwise_data:\n            colwise_data[row[col]] = []\n        if delete:\n            colwise_data[row[col]].append(row[:col] + row[col+1:])\n            del data[i][col]\n        else:\n            colwise_data[row[col]].append(row)\n            \n    return list(colwise_data.keys()), colwise_data\n\ndef entropy(S):\n    \n    count = Counter(S)\n    if len(count.keys()) == 1:\n        return 0\n    \n    entropy = 0\n    for k, v in count.items():\n        p = v / (1.0*len(S))\n        entropy += -1 * p * math.log(p, 2)\n\n    return entropy\n\ndef compute_gain(data,col):\n   \n    values,dic = subtables(data,col,delete=False)\n    total_size=len(data)\n    entropies=[0]*len(values)\n    ratio=[0]*len(values)\n    total_entropy=entropy([row[-1] for row in data])\n    for x in range(len(values)):\n        ratio[x]=len(dic[values[x]])/(total_size*1.0)\n        entropies[x]=entropy([row[-1] for row in dic[values[x]]])\n\n        total_entropy-=ratio[x]*entropies[x]\n    return total_entropy\n\ndef build_tree(data,features):\n    lastcol=[row[-1] for row in data]\n    \n    \n    if(len(set(lastcol)))==1:\n        node=Node(\"\")\n        node.answer=lastcol[0]\n        return node\n    \n    \n    n=len(data[0])-1\n    \n    \n    gains=[0]*n\n    for i in range(n):\n        gains[i]=compute_gain(data,i)\n    \n   \n    split=gains.index(max(gains))\n    \n   \n    node=Node(features[split])\n    \n   \n    fea = features[:split]+features[split+1:]\n    \n   \n    attr,dic=subtables(data,split,delete=True)\n    for x in range(len(attr)):\n        child=build_tree(dic[attr[x]],fea)\n        node.children.append((attr[x],child))\n        \n    return node\n\ndef print_tree(node,level):\n    if node.answer!=\"\":\n        print(\"\\t\"*level,node.answer)\n        return\n    print(\"\\t\"*level,node.attribute)\n    for value,n in node.children:\n        print(\"\\t\"*(level+1),value)\n        print_tree(n,level+2)\n\ndef classify(node,x_test,features):\n    if node.answer!=\"\":\n        print(node.answer)\n        return\n    pos=features.index(node.attribute)\n    for value, n in node.children:\n        if x_test[pos]==value:\n            classify(n,x_test,features)\n\n\ndataset,features=load_csv(\"data3.csv\")\nnode1=build_tree(dataset,features)\nprint(\"The decision tree for the dataset using ID3 algorithm is\")\nprint_tree(node1,0)\ntestdata,features=load_csv(\"data3_test.csv\")\nfor xtest in testdata:\n    print(\"The test instance:\",xtest)\n    print(\"The label for test instance:\",end=\" \")\n    classify(node1,xtest,features)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c0f28c1b"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "ba0ff260-dd76-4c8d-95ee-1f3e1bd6dc05"
    }
  ]
}